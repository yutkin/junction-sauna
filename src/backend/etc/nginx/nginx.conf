worker_processes 1;
user root;

events {
  use epoll;
  multi_accept on;
  worker_connections  4096;
}

# only log critical errors
error_log /var/log/nginx/error.log crit;

http {
    upstream backend {
        # server aiohttp:8080 weight=1;
        server unix:/var/lib/aiohttp/aiohttp_1.sock fail_timeout=0;
        server unix:/var/lib/aiohttp/aiohttp_2.sock fail_timeout=0;
        server unix:/var/lib/aiohttp/aiohttp_3.sock fail_timeout=0;
        server unix:/var/lib/aiohttp/aiohttp_4.sock fail_timeout=0;
    }

    server {
        listen 80;
        server_name snek-gc.misha.im;
        return 301 https://$host$request_uri;
    }

    server {
        listen 443 ssl default deferred;
        server_name snek-gc.misha.im;

        include /etc/nginx/ssl.conf;

        client_max_body_size 1m;

        # to boost I/O on HDD we can disable access logs
        # access_log off;

        # copies data between one FD and other from within the kernel
        # faster then read() + write()
        sendfile on;

        # send headers in one peace, its better then sending them one by one
        tcp_nopush on;

        # don't buffer data sent, good for small data bursts in real time
        tcp_nodelay on;

        # allow the server to close connection on non responding client, this will free up memory
        reset_timedout_connection on;

        # request timed out -- default 60
        client_body_timeout 10;

        # if client stop responding, free up memory -- default 60
        send_timeout 2;

        # server will close connection after this time -- default 75
        keepalive_timeout 30;

        # number of requests client can make over keep-alive -- for testing environment
        keepalive_requests 1000;



        location / {
            proxy_set_header   Host                 $host;
            proxy_set_header   X-Real-IP            $remote_addr;
            proxy_set_header   X-Forwarded-For      $proxy_add_x_forwarded_for;

            proxy_redirect off;
            proxy_buffering off;

            proxy_pass http://backend;
        }
    }
}